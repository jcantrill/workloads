apiVersion: v1
data:
  fluent.conf: |+
    ## CLO GENERATED CONFIGURATION ###
    # This file is a copy of the fluentd configuration entrypoint
    # which should normally be supplied in a configmap.

    <system>
      @log_level "#{ENV['LOG_LEVEL'] || 'warn'}"
    </system>

    # In each section below, pre- and post- includes don't include anything initially;
    # they exist to enable future additions to openshift conf as needed.

    ## sources
    ## ordered so that syslog always runs last...
    <source>
      @type prometheus
      bind ''
      <ssl>
        enable true
        certificate_path "#{ENV['METRICS_CERT'] || '/etc/fluent/metrics/tls.crt'}"
        private_key_path "#{ENV['METRICS_KEY'] || '/etc/fluent/metrics/tls.key'}"
      </ssl>
    </source>

    <source>
      @type prometheus_monitor
      <labels>
        hostname ${hostname}
      </labels>
    </source>

    # excluding prometheus_tail_monitor
    # since it leaks namespace/pod info
    # via file paths

    # This is considered experimental by the repo
    <source>
      @type prometheus_output_monitor
      <labels>
        hostname ${hostname}
      </labels>
    </source>
#    #journal logs to gather node
#    <source>
#      @type systemd
#      @id systemd-input
#      @label @INGRESS
#      path "#{if (val = ENV.fetch('JOURNAL_SOURCE','')) && (val.length > 0); val; else '/run/log/journal'; end}"
#      <storage>
#        @type local
#        persistent true
#        # NOTE: if this does not end in .json, fluentd will think it
#        # is the name of a directory - see fluentd storage_local.rb
#        path "#{ENV['JOURNAL_POS_FILE'] || '/var/log/journal_pos.json'}"
#      </storage>
#      matches "#{ENV['JOURNAL_FILTERS_JSON'] || '[]'}"
#      tag journal
#      read_from_head "#{if (val = ENV.fetch('JOURNAL_READ_FROM_HEAD','')) && (val.length > 0); val; else 'false'; end}"
#    </source>
    # container logs
    <source>
      @type tail
      @id container-input
      path "/var/log/containers/*.log"
#      exclude_path ["/var/log/containers/fluentd-*_openshift-logging_*.log", "/var/log/containers/elasticsearch-*_openshift-logging_*.log", "/var/log/containers/kibana-*_openshift-logging_*.log"]
      exclude_path ["/var/log/containers/*-*_openshift*_*.log", "/var/log/containers/*-*_kube*_*.log", "/var/log/containers/*-*_default_*.log"]
      pos_file "/var/log/es-containers.log.pos"
      refresh_interval 5
      rotate_wait 5
      tag kubernetes.*
      read_from_head "true"
      @label @CONCAT
      <parse>
        @type multi_format
        <pattern>
          format json
          time_format '%Y-%m-%dT%H:%M:%S.%N%Z'
          keep_time_key true
        </pattern>
        <pattern>
          format regexp
          expression /^(?<time>.+) (?<stream>stdout|stderr)( (?<logtag>.))? (?<log>.*)$/
          time_format '%Y-%m-%dT%H:%M:%S.%N%:z'
          keep_time_key true
        </pattern>
      </parse>
    </source>

    <label @CONCAT>
      <filter kubernetes.**>
        @type concat
        key log
        partial_key logtag
        partial_value P
        separator ''
      </filter>
      <match kubernetes.**>
        @type relabel
        @label @INGRESS
      </match>
    </label>

    #syslog input config here

    <label @INGRESS>

      ## filters
      <filter **>
        @type record_modifier
        char_encoding utf-8
      </filter>

      <filter journal>
        @type grep
        <exclude>
          key PRIORITY
          pattern ^7$
        </exclude>
      </filter>

      <match journal>
        @type rewrite_tag_filter
        # skip to @INGRESS label section
        @label @INGRESS

        # see if this is a kibana container for special log handling
        # looks like this:
        # k8s_kibana.a67f366_logging-kibana-1-d90e3_logging_26c51a61-2835-11e6-ad29-fa163e4944d5_f0db49a2
        # we filter these logs through the kibana_transform.conf filter
        <rule>
          key CONTAINER_NAME
          pattern ^k8s_kibana\.
          tag kubernetes.journal.container.kibana
        </rule>

        <rule>
          key CONTAINER_NAME
          pattern ^k8s_[^_]+_logging-eventrouter-[^_]+_
          tag kubernetes.journal.container._default_.kubernetes-event
        </rule>

        # mark logs from default namespace for processing as k8s logs but stored as system logs
        <rule>
          key CONTAINER_NAME
          pattern ^k8s_[^_]+_[^_]+_default_
          tag kubernetes.journal.container._default_
        </rule>

        # mark logs from kube-* namespaces for processing as k8s logs but stored as system logs
        <rule>
          key CONTAINER_NAME
          pattern ^k8s_[^_]+_[^_]+_kube-(.+)_
          tag kubernetes.journal.container._kube-$1_
        </rule>

        # mark logs from openshift-* namespaces for processing as k8s logs but stored as system logs
        <rule>
          key CONTAINER_NAME
          pattern ^k8s_[^_]+_[^_]+_openshift-(.+)_
          tag kubernetes.journal.container._openshift-$1_
        </rule>

        # mark logs from openshift namespace for processing as k8s logs but stored as system logs
        <rule>
          key CONTAINER_NAME
          pattern ^k8s_[^_]+_[^_]+_openshift_
          tag kubernetes.journal.container._openshift_
        </rule>

        # mark fluentd container logs
        <rule>
          key CONTAINER_NAME
          pattern ^k8s_.*fluentd
          tag kubernetes.journal.container.fluentd
        </rule>

        # this is a kubernetes container
        <rule>
          key CONTAINER_NAME
          pattern ^k8s_
          tag kubernetes.journal.container
        </rule>

        # not kubernetes - assume a system log or system container log
        <rule>
          key _TRANSPORT
          pattern .+
          tag journal.system
        </rule>
      </match>

      <filter kubernetes.**>
        @type kubernetes_metadata
        kubernetes_url "#{ENV['K8S_HOST_URL']}"
        cache_size "#{ENV['K8S_METADATA_CACHE_SIZE'] || '1000'}"
        watch "#{ENV['K8S_METADATA_WATCH'] || 'false'}"
        use_journal "#{ENV['USE_JOURNAL'] || 'nil'}"
        ssl_partial_chain "#{ENV['SSL_PARTIAL_CHAIN'] || 'true'}"
      </filter>

      <filter kubernetes.journal.**>
        @type parse_json_field
        merge_json_log "#{ENV['MERGE_JSON_LOG'] || 'false'}"
        preserve_json_log "#{ENV['PRESERVE_JSON_LOG'] || 'true'}"
        json_fields "#{ENV['JSON_FIELDS'] || 'MESSAGE,log'}"
      </filter>

      <filter kubernetes.var.log.containers.**>
        @type parse_json_field
        merge_json_log "#{ENV['MERGE_JSON_LOG'] || 'false'}"
        preserve_json_log "#{ENV['PRESERVE_JSON_LOG'] || 'true'}"
        json_fields "#{ENV['JSON_FIELDS'] || 'log,MESSAGE'}"
      </filter>

      <filter kubernetes.var.log.containers.eventrouter-** kubernetes.var.log.containers.cluster-logging-eventrouter-**>
        @type parse_json_field
        merge_json_log true
        preserve_json_log true
        json_fields "#{ENV['JSON_FIELDS'] || 'log,MESSAGE'}"
      </filter>

      <filter **kibana**>
        @type record_transformer
        enable_ruby
        <record>
          log ${record['err'] || record['msg'] || record['MESSAGE'] || record['log']}
        </record>
        remove_keys req,res,msg,name,level,v,pid,err
      </filter>

      <filter **>
        @type viaq_data_model
        elasticsearch_index_prefix_field 'viaq_index_name'
        default_keep_fields CEE,time,@timestamp,aushape,ci_job,collectd,docker,fedora-ci,file,foreman,geoip,hostname,ipaddr4,ipaddr6,kubernetes,level,message,namespace_name,namespace_uuid,offset,openstack,ovirt,pid,pipeline_metadata,rsyslog,service,systemd,tags,testcase,tlog,viaq_msg_id
        extra_keep_fields "#{ENV['CDM_EXTRA_KEEP_FIELDS'] || ''}"
        keep_empty_fields "#{ENV['CDM_KEEP_EMPTY_FIELDS'] || 'message'}"
        use_undefined "#{ENV['CDM_USE_UNDEFINED'] || false}"
        undefined_name "#{ENV['CDM_UNDEFINED_NAME'] || 'undefined'}"
        rename_time "#{ENV['CDM_RENAME_TIME'] || true}"
        rename_time_if_missing "#{ENV['CDM_RENAME_TIME_IF_MISSING'] || false}"
        src_time_name "#{ENV['CDM_SRC_TIME_NAME'] || 'time'}"
        dest_time_name "#{ENV['CDM_DEST_TIME_NAME'] || '@timestamp'}"
        pipeline_type "#{ENV['PIPELINE_TYPE'] || 'collector'}"
        undefined_to_string "#{ENV['CDM_UNDEFINED_TO_STRING'] || 'false'}"
        undefined_dot_replace_char "#{ENV['CDM_UNDEFINED_DOT_REPLACE_CHAR'] || 'UNUSED'}"
        undefined_max_num_fields "#{ENV['CDM_UNDEFINED_MAX_NUM_FIELDS'] || '-1'}"
        process_kubernetes_events "#{ENV['TRANSFORM_EVENTS'] || 'false'}"
        <formatter>
          tag "system.var.log**"
          type sys_var_log
          remove_keys host,pid,ident
        </formatter>
        <formatter>
          tag "journal.system**"
          type sys_journal
          remove_keys log,stream,MESSAGE,_SOURCE_REALTIME_TIMESTAMP,__REALTIME_TIMESTAMP,CONTAINER_ID,CONTAINER_ID_FULL,CONTAINER_NAME,PRIORITY,_BOOT_ID,_CAP_EFFECTIVE,_CMDLINE,_COMM,_EXE,_GID,_HOSTNAME,_MACHINE_ID,_PID,_SELINUX_CONTEXT,_SYSTEMD_CGROUP,_SYSTEMD_SLICE,_SYSTEMD_UNIT,_TRANSPORT,_UID,_AUDIT_LOGINUID,_AUDIT_SESSION,_SYSTEMD_OWNER_UID,_SYSTEMD_SESSION,_SYSTEMD_USER_UNIT,CODE_FILE,CODE_FUNCTION,CODE_LINE,ERRNO,MESSAGE_ID,RESULT,UNIT,_KERNEL_DEVICE,_KERNEL_SUBSYSTEM,_UDEV_SYSNAME,_UDEV_DEVNODE,_UDEV_DEVLINK,SYSLOG_FACILITY,SYSLOG_IDENTIFIER,SYSLOG_PID
        </formatter>
        <formatter>
          tag "kubernetes.journal.container**"
          type k8s_journal
          remove_keys "#{ENV['K8S_FILTER_REMOVE_KEYS'] || 'log,stream,MESSAGE,_SOURCE_REALTIME_TIMESTAMP,__REALTIME_TIMESTAMP,CONTAINER_ID,CONTAINER_ID_FULL,CONTAINER_NAME,PRIORITY,_BOOT_ID,_CAP_EFFECTIVE,_CMDLINE,_COMM,_EXE,_GID,_HOSTNAME,_MACHINE_ID,_PID,_SELINUX_CONTEXT,_SYSTEMD_CGROUP,_SYSTEMD_SLICE,_SYSTEMD_UNIT,_TRANSPORT,_UID,_AUDIT_LOGINUID,_AUDIT_SESSION,_SYSTEMD_OWNER_UID,_SYSTEMD_SESSION,_SYSTEMD_USER_UNIT,CODE_FILE,CODE_FUNCTION,CODE_LINE,ERRNO,MESSAGE_ID,RESULT,UNIT,_KERNEL_DEVICE,_KERNEL_SUBSYSTEM,_UDEV_SYSNAME,_UDEV_DEVNODE,_UDEV_DEVLINK,SYSLOG_FACILITY,SYSLOG_IDENTIFIER,SYSLOG_PID'}"
        </formatter>
        <formatter>
          tag "kubernetes.var.log.containers.eventrouter-** kubernetes.var.log.containers.cluster-logging-eventrouter-** k8s-audit.log** openshift-audit.log**"
          type k8s_json_file
          remove_keys log,stream,CONTAINER_ID_FULL,CONTAINER_NAME
          process_kubernetes_events "#{ENV['TRANSFORM_EVENTS'] || 'true'}"
        </formatter>
        <formatter>
          tag "kubernetes.var.log.containers**"
          type k8s_json_file
          remove_keys log,stream,CONTAINER_ID_FULL,CONTAINER_NAME
        </formatter>
        <elasticsearch_index_name>
          enabled "#{ENV['ENABLE_ES_INDEX_NAME'] || 'true'}"
          tag "journal.system** system.var.log** **_default_** **_kube-*_** **_openshift-*_** **_openshift_**"
          name_type static
          static_index_name infra-write
        </elasticsearch_index_name>
        <elasticsearch_index_name>
          enabled "#{ENV['ENABLE_ES_INDEX_NAME'] || 'true'}"
          tag "linux-audit.log** k8s-audit.log** openshift-audit.log**"
          name_type static
          static_index_name audit-write
        </elasticsearch_index_name>
        <elasticsearch_index_name>
          enabled "#{ENV['ENABLE_ES_INDEX_NAME'] || 'true'}"
          tag "**"
          name_type static
          static_index_name app-write
        </elasticsearch_index_name>
      </filter>

      <filter **>
        @type elasticsearch_genid_ext
        hash_id_key viaq_msg_id
        alt_key kubernetes.event.metadata.uid
        alt_tags "#{ENV['GENID_ALT_TAG'] || 'kubernetes.var.log.containers.logging-eventrouter-*.** kubernetes.var.log.containers.eventrouter-*.** kubernetes.var.log.containers.cluster-logging-eventrouter-*.** kubernetes.journal.container._default_.kubernetes-event'}"
      </filter>

      #flatten labels to prevent field explosion in ES
      <filter ** >
        @type record_transformer
        enable_ruby true
        <record>
          kubernetes ${!record['kubernetes'].nil? ? record['kubernetes'].merge({"flat_labels": (record['kubernetes']['labels']||{}).map{|k,v| "#{k}=#{v}"}}) : {} }
        </record>
        remove_keys $.kubernetes.labels
      </filter>

      # Relabel specific source tags to specific intermediary labels for copy processing

      <match **_default_** **_kube-*_** **_openshift-*_** **_openshift_** journal.** system.var.log**>
        @type relabel
        @label @_LOGS_INFRA
      </match>

      <match kubernetes.**>
        @type relabel
        @label @_LOGS_APP
      </match>

      <match **>
        @type stdout
      </match>

    </label>

    # Relabel specific sources (e.g. logs.apps) to multiple pipelines
    <label @_LOGS_APP>
      <match **>
        @type copy

        <store>
          @type relabel
          @label @CLO_DEFAULT_APP_PIPELINE
        </store>


      </match>
    </label>
    <label @_LOGS_INFRA>
      <match **>
        @type copy

        <store>
          @type relabel
          @label @CLO_DEFAULT_INFRA_PIPELINE
        </store>


      </match>
    </label>

    # Relabel specific pipelines to multiple, outputs (e.g. ES, kafka stores)
    <label @CLO_DEFAULT_APP_PIPELINE>
      <match **>
        @type copy

        <store>
          @type relabel
          @label @CLO_DEFAULT_OUTPUT_ES
        </store>
      </match>
    </label>
    <label @CLO_DEFAULT_INFRA_PIPELINE>
      <match **>
        @type copy

        <store>
          @type relabel
          @label @CLO_DEFAULT_OUTPUT_ES
        </store>
      </match>
    </label>

    # Ship logs to specific outputs
    <label @CLO_DEFAULT_OUTPUT_ES>
      <match retry_clo_default_output_es>
        @type copy
        <store>
          @type elasticsearch
          @id retry_clo_default_output_es
          host elasticsearch.openshift-logging.svc.cluster.local
          port 9200
          verify_es_version_at_startup false
          scheme https
          ssl_version TLSv1_2
          target_index_key viaq_index_name
          id_key viaq_msg_id
          remove_keys viaq_index_name
          user fluentd
          password changeme
          client_key '/var/run/ocp-collector/secrets/fluentd/tls.key'
          client_cert '/var/run/ocp-collector/secrets/fluentd/tls.crt'
          ca_file '/var/run/ocp-collector/secrets/fluentd/ca-bundle.crt'
          type_name _doc
          write_operation create
          reload_connections "#{ENV['ES_RELOAD_CONNECTIONS'] || 'true'}"
          # https://github.com/uken/fluent-plugin-elasticsearch#reload-after
          reload_after "#{ENV['ES_RELOAD_AFTER'] || '200'}"
          # https://github.com/uken/fluent-plugin-elasticsearch#sniffer-class-name
          sniffer_class_name "#{ENV['ES_SNIFFER_CLASS_NAME'] || 'Fluent::Plugin::ElasticsearchSimpleSniffer'}"
          reload_on_failure false
          # 2 ^ 31
          request_timeout 2147483648
          <buffer>
            @type file
            path '/var/lib/fluentd/retry_clo_default_output_es'
            flush_interval "#{ENV['ES_FLUSH_INTERVAL'] || '1s'}"
            flush_thread_count "#{ENV['ES_FLUSH_THREAD_COUNT'] || 2}"
            flush_at_shutdown "#{ENV['FLUSH_AT_SHUTDOWN'] || 'false'}"
            retry_max_interval "#{ENV['ES_RETRY_WAIT'] || '300'}"
            retry_forever true
            queue_limit_length "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
            chunk_limit_size "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
            overflow_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"
          </buffer>
        </store>
      </match>
      <match **>
        @type copy
        <store>
          @type elasticsearch
          @id clo_default_output_es
          host elasticsearch.openshift-logging.svc.cluster.local
          port 9200
          verify_es_version_at_startup false
          scheme https
          ssl_version TLSv1_2
          target_index_key viaq_index_name
          id_key viaq_msg_id
          remove_keys viaq_index_name
          user fluentd
          password changeme
          client_key '/var/run/ocp-collector/secrets/fluentd/tls.key'
          client_cert '/var/run/ocp-collector/secrets/fluentd/tls.crt'
          ca_file '/var/run/ocp-collector/secrets/fluentd/ca-bundle.crt'
          type_name _doc
          retry_tag retry_clo_default_output_es
          write_operation create
          reload_connections "#{ENV['ES_RELOAD_CONNECTIONS'] || 'true'}"
          # https://github.com/uken/fluent-plugin-elasticsearch#reload-after
          reload_after "#{ENV['ES_RELOAD_AFTER'] || '200'}"
          # https://github.com/uken/fluent-plugin-elasticsearch#sniffer-class-name
          sniffer_class_name "#{ENV['ES_SNIFFER_CLASS_NAME'] || 'Fluent::Plugin::ElasticsearchSimpleSniffer'}"
          reload_on_failure false
          # 2 ^ 31
          request_timeout 2147483648
          <buffer>
            @type file
            path '/var/lib/fluentd/clo_default_output_es'
            flush_interval "#{ENV['ES_FLUSH_INTERVAL'] || '1s'}"
            flush_thread_count "#{ENV['ES_FLUSH_THREAD_COUNT'] || 2}"
            flush_at_shutdown "#{ENV['FLUSH_AT_SHUTDOWN'] || 'false'}"
            retry_max_interval "#{ENV['ES_RETRY_WAIT'] || '300'}"
            retry_forever true
            queue_limit_length "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
            chunk_limit_size "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
            overflow_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"
          </buffer>
        </store>
      </match>
    </label>

  run.sh: |
    #!/bin/bash

    export MERGE_JSON_LOG=${MERGE_JSON_LOG:-false}
    CFG_DIR=/etc/fluent/configs.d
    ENABLE_PROMETHEUS_ENDPOINT=${ENABLE_PROMETHEUS_ENDPOINT:-"true"}
    OCP_OPERATIONS_PROJECTS=${OCP_OPERATIONS_PROJECTS:-"default openshift openshift- kube-"}

    fluentdargs="--no-supervisor"
    # find the sniffer class file
    sniffer=$( gem contents fluent-plugin-elasticsearch|grep elasticsearch_simple_sniffer.rb )
    if [ -z "$sniffer" ] ; then
        sniffer=$( rpm -ql rubygem-fluent-plugin-elasticsearch|grep elasticsearch_simple_sniffer.rb )
    fi
    if [ -n "$sniffer" -a -f "$sniffer" ] ; then
        fluentdargs="$fluentdargs -r $sniffer"
    fi

    if [[ $VERBOSE ]]; then
      set -ex
      fluentdargs="$fluentdargs -vv --log-event-verbose"
      echo ">>>>>> ENVIRONMENT VARS <<<<<"
      env | sort
      echo ">>>>>>>>>>>>><<<<<<<<<<<<<<<<"
    else
      set -e
      fluentdargs="-q --suppress-config-dump $fluentdargs"
    fi


    issue_deprecation_warnings() {
        : # none at the moment
    }

    if [ -z "${JOURNAL_SOURCE:-}" ] ; then
        if [ -d /var/log/journal ] ; then
            export JOURNAL_SOURCE=/var/log/journal
        else
            export JOURNAL_SOURCE=/run/log/journal
        fi
    fi

    IPADDR4=${NODE_IPV4:-$( /usr/sbin/ip -4 addr show dev eth0 | grep inet | sed -e "s/[ \t]*inet \([0-9.]*\).*/\1/" )}
    IPADDR6=${NODE_IPV6:-$( /usr/sbin/ip -6 addr show dev eth0 | grep inet | sed -e "s/[ \t]*inet6 \([a-z0-9::]*\).*/\1/" | grep -v ^fe80 | grep -v ^::1 || echo "")}

    export IPADDR4 IPADDR6

    BUFFER_SIZE_LIMIT=${BUFFER_SIZE_LIMIT:-16777216}

    # Generate throttle configs and outputs
    ruby generate_throttle_configs.rb
    # have output plugins handle back pressure
    # if you want the old behavior to be forced anyway, set env
    # BUFFER_QUEUE_FULL_ACTION=exception
    export BUFFER_QUEUE_FULL_ACTION=${BUFFER_QUEUE_FULL_ACTION:-block}

    # this is the list of keys to remove when the record is transformed from the raw systemd journald
    # output to the viaq data model format
    K8S_FILTER_REMOVE_KEYS="log,stream,MESSAGE,_SOURCE_REALTIME_TIMESTAMP,__REALTIME_TIMESTAMP,CONTAINER_ID,CONTAINER_ID_FULL,CONTAINER_NAME,PRIORITY,_BOOT_ID,_CAP_EFFECTIVE,_CMDLINE,_COMM,_EXE,_GID,_HOSTNAME,_MACHINE_ID,_PID,_SELINUX_CONTEXT,_SYSTEMD_CGROUP,_SYSTEMD_SLICE,_SYSTEMD_UNIT,_TRANSPORT,_UID,_AUDIT_LOGINUID,_AUDIT_SESSION,_SYSTEMD_OWNER_UID,_SYSTEMD_SESSION,_SYSTEMD_USER_UNIT,CODE_FILE,CODE_FUNCTION,CODE_LINE,ERRNO,MESSAGE_ID,RESULT,UNIT,_KERNEL_DEVICE,_KERNEL_SUBSYSTEM,_UDEV_SYSNAME,_UDEV_DEVNODE,_UDEV_DEVLINK,SYSLOG_FACILITY,SYSLOG_IDENTIFIER,SYSLOG_PID"
    export K8S_FILTER_REMOVE_KEYS ENABLE_ES_INDEX_NAME

    # Check bearer_token_file for fluent-plugin-kubernetes_metadata_filter.
    if [ ! -s /var/run/secrets/kubernetes.io/serviceaccount/token ] ; then
        echo "ERROR: Bearer_token_file (/var/run/secrets/kubernetes.io/serviceaccount/token) to access the Kubernetes API server is missing or empty."
        exit 1
    fi

    # If FILE_BUFFER_PATH exists and it is not a directory, mkdir fails with the error.
    FILE_BUFFER_PATH=/var/lib/fluentd
    mkdir -p $FILE_BUFFER_PATH

    FLUENT_CONF=$CFG_DIR/user/fluent.conf
    if [ ! -f "$FLUENT_CONF" ] ; then
        echo "ERROR: The configuration $FLUENT_CONF does not exist"
        exit 1
    fi
    NUM_OUTPUTS=$(grep "path.*'$FILE_BUFFER_PATH" $FLUENT_CONF | wc -l)
    if [ $NUM_OUTPUTS -eq 0 ]; then
        # Reset to default single output if log forwarding outputs all invalid
        NUM_OUTPUTS=1
    fi

    # Get the available disk size.
    DF_LIMIT=$(df -B1 $FILE_BUFFER_PATH | grep -v Filesystem | awk '{print $2}')
    DF_LIMIT=${DF_LIMIT:-0}
    if [ $DF_LIMIT -eq 0 ]; then
        echo "ERROR: No disk space is available for file buffer in $FILE_BUFFER_PATH."
        exit 1
    fi
    # Determine final total given the number of outputs we have.
    TOTAL_LIMIT=$(echo ${FILE_BUFFER_LIMIT:-2Gi} | sed -e "s/[Kk]/*1024/g;s/[Mm]/*1024*1024/g;s/[Gg]/*1024*1024*1024/g;s/i//g" | bc) || :
    if [ $TOTAL_LIMIT -le 0 ]; then
        echo "ERROR: Invalid file buffer limit ($FILE_BUFFER_LIMIT) is given.  Failed to convert to bytes."
        exit 1
    fi

    TOTAL_LIMIT=$(expr $TOTAL_LIMIT \* $NUM_OUTPUTS) || :
    if [ $DF_LIMIT -lt $TOTAL_LIMIT ]; then
        echo "WARNING: Available disk space ($DF_LIMIT bytes) is less than the user specified file buffer limit ($FILE_BUFFER_LIMIT times $NUM_OUTPUTS)."
        TOTAL_LIMIT=$DF_LIMIT
    fi

    BUFFER_SIZE_LIMIT=$(echo $BUFFER_SIZE_LIMIT |  sed -e "s/[Kk]/*1024/g;s/[Mm]/*1024*1024/g;s/[Gg]/*1024*1024*1024/g;s/i//g" | bc)
    BUFFER_SIZE_LIMIT=${BUFFER_SIZE_LIMIT:-16777216}

    # TOTAL_BUFFER_SIZE_LIMIT per buffer
    TOTAL_BUFFER_SIZE_LIMIT=$(expr $TOTAL_LIMIT / $NUM_OUTPUTS) || :
    if [ -z $TOTAL_BUFFER_SIZE_LIMIT -o $TOTAL_BUFFER_SIZE_LIMIT -eq 0 ]; then
        echo "ERROR: Calculated TOTAL_BUFFER_SIZE_LIMIT is 0. TOTAL_LIMIT $TOTAL_LIMIT is too small compared to NUM_OUTPUTS $NUM_OUTPUTS. Please increase FILE_BUFFER_LIMIT $FILE_BUFFER_LIMIT and/or the volume size of $FILE_BUFFER_PATH."
        exit 1
    fi
    BUFFER_QUEUE_LIMIT=$(expr $TOTAL_BUFFER_SIZE_LIMIT / $BUFFER_SIZE_LIMIT) || :
    if [ -z $BUFFER_QUEUE_LIMIT -o $BUFFER_QUEUE_LIMIT -eq 0 ]; then
        echo "ERROR: Calculated BUFFER_QUEUE_LIMIT is 0. TOTAL_BUFFER_SIZE_LIMIT $TOTAL_BUFFER_SIZE_LIMIT is too small compared to BUFFER_SIZE_LIMIT $BUFFER_SIZE_LIMIT. Please increase FILE_BUFFER_LIMIT $FILE_BUFFER_LIMIT and/or the volume size of $FILE_BUFFER_PATH."
        exit 1
    fi
    export BUFFER_QUEUE_LIMIT BUFFER_SIZE_LIMIT

    # http://docs.fluentd.org/v0.12/articles/monitoring
    if [ "${ENABLE_MONITOR_AGENT:-}" = true ] ; then
        cp $CFG_DIR/input-pre-monitor.conf $CFG_DIR/openshift
        # copy any user defined files, possibly overwriting the standard ones
        if [ -f $CFG_DIR/user/input-pre-monitor.conf ] ; then
            cp -f $CFG_DIR/user/input-pre-monitor.conf $CFG_DIR/openshift
        fi
    else
        rm -f $CFG_DIR/openshift/input-pre-monitor.conf
    fi

    # http://docs.fluentd.org/v0.12/articles/monitoring#debug-port
    if [ "${ENABLE_DEBUG_AGENT:-}" = true ] ; then
        cp $CFG_DIR/input-pre-debug.conf $CFG_DIR/openshift
        # copy any user defined files, possibly overwriting the standard ones
        if [ -f $CFG_DIR/user/input-pre-debug.conf ] ; then
            cp -f $CFG_DIR/user/input-pre-debug.conf $CFG_DIR/openshift
        fi
    else
        rm -f $CFG_DIR/openshift/input-pre-debug.conf
    fi

    # bug https://bugzilla.redhat.com/show_bug.cgi?id=1437952
    # pods unable to be terminated because fluentd has them busy
    if [ -d /var/lib/docker/containers ] ; then
        # If oci-umount is fixed, we can remove this.
        if [ -n "${VERBOSE:-}" ] ; then
            echo "umounts of dead containers will fail. Ignoring..."
            umount /var/lib/docker/containers/*/shm || :
        else
            umount /var/lib/docker/containers/*/shm > /dev/null 2>&1 || :
        fi
    fi

    if [ "${AUDIT_CONTAINER_ENGINE:-}" = "true" ] ; then
        cp -f $CFG_DIR/input-pre-audit-log.conf $CFG_DIR/openshift
        cp -f $CFG_DIR/filter-pre-a-audit-exclude.conf $CFG_DIR/openshift
    else
        touch $CFG_DIR/openshift/input-pre-audit-log.conf
        touch $CFG_DIR/openshift/filter-pre-a-audit-exclude.conf
    fi

    if [ "${ENABLE_UTF8_FILTER:-}" != true ] ; then
        rm -f $CFG_DIR/openshift/filter-pre-force-utf8.conf
        touch $CFG_DIR/openshift/filter-pre-force-utf8.conf
    fi

    # Include DEBUG log level messages when collecting from journald
    # https://bugzilla.redhat.com/show_bug.cgi?id=1505602
    if [ "${COLLECT_JOURNAL_DEBUG_LOGS:-true}" = true ] ; then
      rm -f $CFG_DIR/openshift/filter-exclude-journal-debug.conf
      touch $CFG_DIR/openshift/filter-exclude-journal-debug.conf
    fi

    if [ "${ENABLE_PROMETHEUS_ENDPOINT}" != "true" ] ; then
      echo "INFO: Disabling Prometheus endpoint"
      rm -f ${CFG_DIR}/openshift/input-pre-prometheus-metrics.conf
    fi

    # convert journal.pos file to new format
    if [ -f /var/log/journal.pos -a ! -f /var/log/journal_pos.json ] ; then
        echo Converting old fluent-plugin-systemd pos file format to new format
        cursor=$( cat /var/log/journal.pos )
        echo '{"journal":"'"$cursor"'"}' > /var/log/journal_pos.json
        rm /var/log/journal.pos
    fi

    issue_deprecation_warnings

    # this should be the last thing before launching fluentd so as not to use
    # jemalloc with any other processes
    if type -p jemalloc-config > /dev/null 2>&1 && [ "${USE_JEMALLOC:-true}" = true ] ; then
        export LD_PRELOAD=$( jemalloc-config --libdir )/libjemalloc.so.$( jemalloc-config --revision )
        export LD_BIND_NOW=1 # workaround for https://bugzilla.redhat.com/show_bug.cgi?id=1544815
    fi
    exec fluentd $fluentdargs
  throttle-config.yaml: |
    # Logging example fluentd throttling config file

    #example-project:
    #  read_lines_limit: 10
    #
    #.operations:
    #  read_lines_limit: 100
kind: ConfigMap
metadata:
  creationTimestamp: "2020-06-15T13:51:16Z"
  name: fluentd
  namespace: openshift-logging
  ownerReferences:
  - apiVersion: logging.openshift.io/v1
    controller: true
    kind: ClusterLogging
    name: instance
    uid: 22ae5309-38b3-441a-a5d2-66f9c62c4589
  resourceVersion: "55307"
  selfLink: /api/v1/namespaces/openshift-logging/configmaps/fluentd
  uid: 7b3a2d1b-4fd1-4eeb-87aa-ad8e10e6a623
